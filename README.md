# ğŸš€ **SynapticFlow** - AI Agent Platform for Everyone

## ğŸ“‹ Project Overview

**SynapticFlow: Making MCP Tool Integration Accessible to All Users**

SynapticFlow is a desktop AI agent platform designed to solve two critical problems in the AI ecosystem:

1. **Accessibility Gap**: MCP (Model Context Protocol) tools are powerful but primarily accessible to developers. We make these tools available to general users through an intuitive interface.

2. **LLM Provider Lock-in**: Users shouldn't be restricted to a few major LLM providers. SynapticFlow provides freedom to choose from multiple providers, including increasingly powerful local LLMs.

## ğŸ¯ What Problems We Solve

### ğŸ”§ **MCP Tool Integration Made Simple**

- **Problem**: MCP tools require technical setup and command-line knowledge
- **Solution**: Built-in tools and easy MCP server management with GUI
- **Benefit**: Anyone can use powerful tools without technical barriers

### ğŸ”“ **Freedom from LLM Vendor Lock-in**

- **Problem**: Most AI platforms tie users to specific LLM providers
- **Solution**: Support for multiple providers (OpenAI, Anthropic, Groq, local models, etc.)
- **Benefit**: Choose the best model for your needs and budget

### ğŸ¤– **Personalized AI Agents**

- **Problem**: Generic AI assistants don't fit specific workflows
- **Solution**: Create custom agents with unique personalities and tool access
- **Benefit**: AI that works exactly how you want it to

## ğŸ›  What We Provide

### âœ… **Comprehensive Built-in Tool Ecosystem**

**ğŸ›¡ï¸ Secure File Management:**

- **SecureFileManager**: Advanced path validation and sandboxed operations
- **Content Store**: Upload, index, and full-text search across PDF, DOCX, XLSX files
- **File Attachments**: Smart MIME type handling with preview capabilities
- **Document Processing**: Extract and analyze content from multiple formats

**âš¡ Code Execution & Development:**

- **Python Sandbox**: Secure code execution with real-time result capture
- **TypeScript Runtime**: JavaScript/TypeScript evaluation environment
- **Output Management**: Comprehensive execution logging and error handling
- **Development Tools**: Built-in debugging and testing utilities

**ğŸŒ Browser Automation:**

- **Interactive Browser Server**: Automated web interactions and scraping
- **Session Management**: Persistent browser sessions with state management
- **Content Extraction**: Clean markdown conversion from web pages
- **Web Integration**: Seamless web data processing pipeline

**ğŸ”— Advanced MCP Integration:**

- **Dual Backend Support**: Both Rust Tauri and Web Worker implementations
- **Security Validation**: Built-in SecurityValidator with comprehensive protection
- **Tool Execution Context**: Unified calling interface across all backends
- **Error Normalization**: Robust error handling and reporting system

### âœ… **Advanced Multi-LLM Ecosystem**

**8 Major Providers, 50+ Models:**

- **ğŸ¤– OpenAI**: GPT-4.1 series, o3/o4-mini reasoning models, GPT-4o variants
- **ğŸ§  Anthropic**: Claude 4 Opus/Sonnet, Claude 3.5 series with advanced tool calling
- **ğŸš€ Google**: Gemini 2.5 Pro/Flash (2M context), Gemini 2.0 agentic models
- **âš¡ Groq**: Llama 3.3 70B, DeepSeek R1 Distill, Qwen3 32B reasoning (1,800+ tokens/sec)
- **ğŸ”¥ Fireworks**: DeepSeek R1, Qwen3 235B MoE, Llama 4 Maverick/Scout
- **ğŸ§  Cerebras**: Ultra-fast inference with industry-leading speed
- **ğŸ  Ollama**: Local models with zero cost (Llama, Mistral, Qwen, CodeLlama)
- **ğŸ¯ Empty**: Custom provider configurations

**Advanced Features:**

- **ğŸ¤” Reasoning Models**: o3, DeepSeek R1, Qwen3 thinking models for complex problem-solving
- **ğŸ’° Cost Optimization**: Real-time cost tracking and model comparison
- **ğŸ“š Massive Context**: Up to 2M tokens (Gemini 2.5 Pro)
- **ğŸ‘ï¸ Multimodal**: Vision, document processing, and code understanding

### âœ… **User-Friendly Features**

- **ğŸ¤– Custom Agents**: Create AI assistants with specific roles and tool access
- **ğŸ‘¥ Multi-Agent Collaboration**: Multiple agents working together on complex tasks
- **ğŸ’¬ Session Management**: Organize conversations with file attachments and context
- **ğŸ“¤ Export/Import**: Share agent configurations and setups with others
- **ğŸ¨ Modern UI**: Clean, terminal-style interface that's both powerful and intuitive

## ğŸ›  Advanced Technology Stack

**Core Framework:**

- **Tauri 2.x**: Latest cross-platform framework with enhanced security and performance
- **React 18.3**: Modern UI with concurrent features and advanced hooks
- **TypeScript 5.6**: Latest language features with strict type safety
- **RMCP 0.2.1**: Rust-based Model Context Protocol with child process transport

**Backend Technologies:**

- **Rust**: High-performance native operations with async/await architecture
- **Tokio**: Advanced async runtime for concurrent MCP server management
- **SecurityValidator**: Built-in path validation and process sandboxing
- **Warp**: HTTP server infrastructure for browser automation capabilities

**Frontend Technologies:**

- **Tailwind CSS 4.x**: Latest utility-first styling with performance optimizations
- **Radix UI**: Accessible component primitives for robust UI
- **Dexie**: TypeScript-friendly IndexedDB wrapper for local data
- **Zustand**: Lightweight, scalable state management solution

## ğŸ›¡ï¸ Security & Performance

**Built-in Security:**

- **SecurityValidator**: Advanced path traversal protection and sandboxed operations
- **MIME Type Validation**: Safe file handling across all supported formats
- **Process Isolation**: MCP servers run in isolated child processes for maximum security
- **API Key Management**: Secure in-app credential storage with encryption
- **Content Sanitization**: Automatic cleaning and validation of all user inputs

**Performance Optimizations:**

- **Streaming Responses**: Real-time AI model outputs with minimal latency
- **Concurrent Tool Execution**: Parallel MCP server operations for faster results
- **Smart Caching**: Intelligent resource caching for improved response times
- **Memory Management**: Optimized for long-running sessions and large datasets
- **Ultra-Fast Models**: Cerebras integration delivering 1,800+ tokens/second

## ğŸ“ Project Structure

```bash
synaptic-flow/
â”œâ”€â”€ src/                        # React Frontend (Feature-Driven Architecture)
â”‚   â”œâ”€â”€ app/                    # App entry, root layout, global providers
â”‚   â”‚   â”œâ”€â”€ App.tsx             # Main application component
â”‚   â”‚   â”œâ”€â”€ main.tsx            # React entry point
â”‚   â”‚   â””â”€â”€ globals.css         # Global styles
â”‚   â”œâ”€â”€ assets/                 # Static assets (images, svgs)
â”‚   â”œâ”€â”€ components/             # Shared UI components (20+ shadcn/ui components)
â”‚   â”‚   â”œâ”€â”€ ui/                 # shadcn/ui component library
â”‚   â”‚   â”œâ”€â”€ layout/             # App layout components
â”‚   â”‚   â””â”€â”€ common/             # Reusable common components
â”‚   â”œâ”€â”€ features/               # Feature modules (7 major features)
â”‚   â”‚   â”œâ”€â”€ assistant/          # AI agent management and configuration
â”‚   â”‚   â”œâ”€â”€ chat/               # Real-time chat interface with tool calling
â”‚   â”‚   â”œâ”€â”€ group/              # Multi-agent collaboration system
â”‚   â”‚   â”œâ”€â”€ history/            # Conversation history and search
â”‚   â”‚   â”œâ”€â”€ prompts/            # Prompt management and templates
â”‚   â”‚   â”œâ”€â”€ session/            # Session management with file attachments
â”‚   â”‚   â”œâ”€â”€ settings/           # Configuration and API key management
â”‚   â”‚   â””â”€â”€ tools/              # Built-in tool ecosystem and MCP integration
â”‚   â”œâ”€â”€ context/                # React context system (8 specialized contexts)
â”‚   â”‚   â”œâ”€â”€ AssistantContext.tsx   # Agent state management
â”‚   â”‚   â”œâ”€â”€ BuiltInToolContext.tsx # Tool execution context
â”‚   â”‚   â”œâ”€â”€ MCPServerContext.tsx   # MCP server management
â”‚   â”‚   â””â”€â”€ ...                   # Additional contexts
â”‚   â”œâ”€â”€ hooks/                  # Custom React hooks
â”‚   â”‚   â”œâ”€â”€ use-rust-backend.ts    # Tauri backend integration
â”‚   â”‚   â”œâ”€â”€ use-mcp-server.ts      # MCP server management
â”‚   â”‚   â””â”€â”€ ...                   # Feature-specific hooks
â”‚   â”œâ”€â”€ lib/                    # Service layer and business logic
â”‚   â”‚   â”œâ”€â”€ ai-service.ts          # LLM provider integration
â”‚   â”‚   â”œâ”€â”€ logger.ts              # Centralized logging system
â”‚   â”‚   â”œâ”€â”€ secure-file-manager.ts # Advanced file operations
â”‚   â”‚   â”œâ”€â”€ rust-backend-client.ts # Backend communication layer
â”‚   â”‚   â””â”€â”€ ...                   # Additional services
â”‚   â”œâ”€â”€ models/                 # TypeScript type definitions
â”‚   â”‚   â”œâ”€â”€ chat.ts               # Chat and message types
â”‚   â”‚   â”œâ”€â”€ mcp-types.ts          # MCP protocol types (680+ lines)
â”‚   â”‚   â””â”€â”€ llm-config.ts         # LLM configuration types
â”‚   â””â”€â”€ config/                 # Configuration files
â”‚       â””â”€â”€ llm-providers.json    # LLM provider definitions
â”œâ”€â”€ src-tauri/                 # Rust Backend (Advanced Architecture)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ lib.rs                 # Main Tauri application
â”‚   â”‚   â”œâ”€â”€ mcp/                   # MCP server integration modules
â”‚   â”‚   â”œâ”€â”€ security/              # Security validation and sandboxing
â”‚   â”‚   â”œâ”€â”€ tools/                 # Built-in tool implementations
â”‚   â”‚   â””â”€â”€ commands/              # Tauri command definitions
â”‚   â”œâ”€â”€ Cargo.toml             # Rust dependencies
â”‚   â””â”€â”€ tauri.conf.json        # Tauri 2.x configuration
â”œâ”€â”€ docs/                      # Documentation and guides
â”‚   â””â”€â”€ history/               # Refactoring and change history
â”œâ”€â”€ package.json               # Node.js dependencies and scripts
â”œâ”€â”€ tailwind.config.js         # Tailwind CSS 4.x configuration
â””â”€â”€ vite.config.ts             # Vite build configuration
```

## ğŸš€ Getting Started

Ready to use SynapticFlow? Here's how to get up and running:

### Option 1: Download Release (Recommended)

Visit our [Releases](https://github.com/SynapticFlow/SynapticFlow/releases) page to download the latest version for your operating system.

### Option 2: Build from Source

1. **Prerequisites**: Ensure you have [Rust](https://rustup.rs/), [Node.js](https://nodejs.org/) (v18+), and [pnpm](https://pnpm.io/) installed.

2. **Install Dependencies**:

   ```bash
   pnpm install
   ```

3. **Development Commands**:

   ```bash
   # Development
   pnpm tauri dev              # Start development server with hot reload
   pnpm dev                    # Frontend-only development mode

   # Code Quality
   pnpm lint                   # ESLint checking with strict rules
   pnpm lint:fix              # Auto-fix lint issues
   pnpm format                # Prettier formatting
   pnpm format:check          # Check formatting compliance

   # Testing & Building
   pnpm test                  # Run comprehensive test suite
   pnpm build                 # Production build optimization
   pnpm tauri build          # Create optimized desktop app bundle

   # Diagnostics
   pnpm diagnose             # System diagnostic for troubleshooting
   ```

### Next Steps

1. **Configure Your First LLM**: Open Settings and add your preferred AI provider's API key
2. **Create an Agent**: Set up your first AI assistant with specific tools and personality
3. **Connect MCP Tools**: Add external MCP servers or use our built-in tools
4. **Start Collaborating**: Begin conversations with your AI agents

## ğŸ”¥ Performance Highlights

**Speed & Efficiency:**

- **âš¡ Ultra-Fast Models**: Cerebras delivering 1,800+ tokens/second
- **ğŸ’° Cost Optimization**: 60-80% cost reduction with smart model selection
- **ğŸš€ Concurrent Operations**: Parallel tool execution for faster results
- **ğŸ¤¯ Massive Context**: Handle up to 2M tokens in single conversations

## ğŸ“š Documentation

- **ğŸ“– [User Guide](docs/guides/getting-started.md)**: Complete setup and usage instructions
- **ğŸ—ï¸ [Architecture](docs/app-architecture.md)**: Technical details for developers
- **ğŸ”§ [MCP Integration](docs/mcp.md)**: How to connect and use MCP servers
- **â“ [Troubleshooting](docs/guides/troubleshooting.md)**: Common issues and solutions
- **ğŸ“ˆ [Refactoring History](docs/history/)**: Detailed change logs and improvements

## ğŸ¤ Contributing

We welcome contributions! Here's how you can help:

- **ğŸ› Report Issues**: Found a bug? [Open an issue](https://github.com/SynapticFlow/SynapticFlow/issues)
- **ğŸ’¡ Suggest Features**: Have ideas? Share them in our discussions
- **ğŸ”§ Submit Code**: Read our [Contributing Guide](CONTRIBUTING.md) to get started
- **ğŸ“š Improve Docs**: Help make our documentation even better

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸŒŸ Support

If SynapticFlow helps you work more efficiently with AI tools, consider:

- â­ **Star this repository** to show your support
- ğŸ—£ï¸ **Share** with others who might find it useful
- ğŸ› **Report issues** to help us improve
- ğŸ’¬ **Join discussions** to shape the future of the project

---

**Ready to experience the most advanced AI agent platform? SynapticFlow combines enterprise-grade security, lightning-fast performance, and unlimited LLM freedom in one powerful desktop application!** ğŸš€

[Download SynapticFlow](https://github.com/SynapticFlow/SynapticFlow/releases) | [View Source](https://github.com/SynapticFlow/SynapticFlow) | [Join Community](https://github.com/SynapticFlow/SynapticFlow/discussions)
