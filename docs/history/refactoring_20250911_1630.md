# Gemini API 호출 안정성 강화를 위한 리팩토링 계획

## 작업의 목적

Gemini API 호출 시 발생하는 `MALFORMED_FUNCTION_CALL` 및 `500 INTERNAL` 오류를 해결하여 AI 서비스의 안정성과 신뢰성을 향상시킵니다.

## 현재의 상태 / 문제점

### 1. MALFORMED_FUNCTION_CALL 오류

- **발생 위치**: Gemini API 함수 호출 처리 중
- **원인**:
  - 불완전한 tool_calls/tool_result 메시지 페어
  - 잘못된 함수 호출 파라미터 직렬화
  - 툴 응답의 JSON 파싱 실패

### 2. 500 INTERNAL 오류

- **발생 위치**: Gemini API 요청 시
- **원인**:
  - 프롬프트 토큰 수 초과 (관찰된 사례: 10,424 토큰)
  - 대용량 툴 응답 누적
  - 컨텍스트 윈도우 제한 위반

### 3. 에러 로그 분석 결과

```
[2025-09-11][01:39:11][webview][ERROR] [BaseAIService] gemini streaming failed
{"error":"got status: INTERNAL. {\"error\":{\"code\":500,\"message\":\"An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting\",\"status\":\"INTERNAL\"}}"}
"finishReason":"MALFORMED_FUNCTION_CALL"
"promptTokenCount":10424
```

## 추가 분석 과제

1. **토큰 계산 정확성 검증**
   - 현재 `estimateTokensBPE` 함수의 정확도 확인
   - Gemini API의 실제 토큰 카운팅과 비교 분석

2. **툴 응답 크기 분석**
   - 어떤 툴이 대용량 응답을 생성하는지 식별
   - 툴 응답 압축 또는 요약 방안 검토

3. **메시지 패턴 분석**
   - 어떤 메시지 시퀀스에서 오류가 자주 발생하는지 패턴 분석
   - 특정 툴 조합에서의 문제 발생 빈도 조사

## 변경 이후의 상태 / 해결 판정 기준

### 성공 기준

1. **MALFORMED_FUNCTION_CALL 오류 제거**: 함수 호출 관련 오류 발생률 < 1%
2. **500 INTERNAL 오류 감소**: 토큰 초과로 인한 오류 발생률 < 2%
3. **서비스 연속성 보장**: 오류 발생 시 자동 복구 성공률 > 90%
4. **사용자 경험 개선**: 채팅 세션 중단 없이 대화 지속 가능

### 측정 방법

- 에러 로그 모니터링 및 통계 수집
- 토큰 사용량 추적 및 최적화 효과 측정
- 사용자 세션 연속성 메트릭 수집

## 수정이 필요한 코드 및 수정부분의 코드 스니핏

### 1. `src/hooks/use-ai-service.ts` - 메시지 검증 및 토큰 관리

**추가할 함수들:**

```typescript
// Tool use pairs validation
function allToolUsePairsAreValid(messages: Message[]): boolean {
  // tool_calls와 대응하는 tool 응답 검증 로직
}

// Invalid tool pairs removal
function removeInvalidToolUseAndToolResponse(messages: Message[]): Message[] {
  // 불완전한 tool/assistant 페어 제거 로직
}

// Token-based message trimming
function trimMessagesToMaxTokens(
  messages: Message[],
  maxTokens: number,
): Message[] {
  // 토큰 한도에 맞는 메시지 트리밍 로직 (tool 페어 우선 제거)
}
```

**수정할 submit 함수 부분:**

```typescript
// Before: 기존 코드
const contextMessages = selectMessagesWithinContext(
  processedMessages,
  provider,
  model,
);

// After: 개선된 코드
let validMessages = processedMessages;
if (!allToolUsePairsAreValid(validMessages)) {
  validMessages = removeInvalidToolUseAndToolResponse(validMessages);
}

let contextMessages = selectMessagesWithinContext(
  validMessages,
  provider,
  model,
);
const maxTokens = config?.maxTokens ?? 4096;
contextMessages = trimMessagesToMaxTokens(contextMessages, maxTokens);
```

### 2. `src/lib/ai-service/gemini.ts` - 함수 호출 안전성 강화

**수정할 streamChat 함수 부분:**

```typescript
// Before: 기존 함수 호출 처리
if (chunk.functionCalls && chunk.functionCalls.length > 0) {
  yield JSON.stringify({
    tool_calls: chunk.functionCalls.map((fc: FunctionCall) => ({
      id: this.generateToolCallId(),
      type: 'function',
      function: {
        name: fc.name,
        arguments: JSON.stringify(fc.args),
      },
    })),
  });
}

// After: 안전성 강화된 처리
if (chunk.functionCalls && chunk.functionCalls.length > 0) {
  const validFunctionCalls = chunk.functionCalls.filter(
    (fc) => fc.name && typeof fc.name === 'string' && fc.args,
  );

  if (validFunctionCalls.length > 0) {
    yield JSON.stringify({
      tool_calls: validFunctionCalls.map((fc: FunctionCall) => {
        let argumentsStr: string;
        try {
          argumentsStr = JSON.stringify(fc.args || {});
        } catch (error) {
          logger.warn('Failed to serialize function arguments', { fc, error });
          argumentsStr = '{}';
        }

        return {
          id: this.generateToolCallId(),
          type: 'function',
          function: { name: fc.name, arguments: argumentsStr },
        };
      }),
    });
  }
}
```

**추가할 에러 처리:**

```typescript
} catch (error) {
  // Gemini 특화 에러 처리
  if (error instanceof Error && error.message.includes('malformed_function_call')) {
    logger.warn('MALFORMED_FUNCTION_CALL detected, retrying without tools');
    if (options.availableTools?.length) {
      const retryOptions = { ...options, availableTools: [] };
      yield* this.streamChat(messages, retryOptions);
      return;
    }
  }

  this.handleStreamingError(error, { messages: validatedMessages, options, config });
}
```

## 재사용 가능한 연관 코드

### 기존 유틸리티 활용

- **파일**: `src/lib/token-utils.ts`
  - `estimateTokensBPE(message: Message)`: 토큰 수 계산
  - `selectMessagesWithinContext()`: 컨텍스트 윈도우 관리
  - `removeIncompleteToolChains()`: 불완전한 툴 체인 제거

### 로깅 시스템 활용

- **파일**: `src/lib/logger.ts`
  - `getLogger(context: string)`: 컨텍스트별 로거 생성
  - 구조화된 로깅으로 디버깅 및 모니터링 지원

### 에러 처리 기반

- **파일**: `src/lib/ai-service/base-service.ts`
  - `handleStreamingError()`: 스트리밍 에러 처리
  - `withRetry()`: 재시도 메커니즘

### 메시지 정규화

- **파일**: `src/lib/ai-service/message-normalizer.ts`
  - `MessageNormalizer.sanitizeForGemini()`: Gemini 특화 메시지 정제
  - 기존 sanitization 로직과 통합

## 구현 순서

### Phase 1: 메시지 검증 및 정리 (우선순위: 높음)

1. `use-ai-service.ts`에 tool pair 검증 함수 구현
2. 불완전한 페어 제거 로직 추가
3. 기존 테스트 케이스로 검증

### Phase 2: 토큰 관리 강화 (우선순위: 높음)

1. 토큰 기반 메시지 트리밍 함수 구현
2. `selectMessagesWithinContext`와 통합
3. 토큰 사용량 모니터링 추가

### Phase 3: Gemini 특화 처리 (우선순위: 중간)

1. `gemini.ts`에 함수 호출 검증 로직 추가
2. 에러 처리 및 재시도 메커니즘 구현
3. 로깅 강화로 디버깅 개선

### Phase 4: 테스트 및 모니터링 (우선순위: 중간)

1. 각 단계별 단위 테스트 작성
2. 통합 테스트로 전체 플로우 검증
3. 프로덕션 환경 모니터링 설정

## 리스크 및 고려사항

### 리스크

- 메시지 트리밍으로 인한 컨텍스트 손실 가능성
- 함수 호출 재시도 시 응답 시간 증가
- 기존 코드와의 호환성 문제

### 완화 방안

- 점진적 배포로 영향도 최소화
- A/B 테스트로 성능 비교 분석
- 기존 동작 보존을 위한 feature flag 활용
