# Anthropic Service 모델 로딩 메커니즘 개선 Refactoring 계획

## 1. 작업의 목적

Anthropic API에서 동적으로 모델 정보를 조회하고, 사고 확장(thinking) 기능 활성화 판정을 메타데이터 기반으로 개선하여, 새로운 모델 출시 시 자동으로 대응할 수 있도록 합니다.

**목표:**

- Anthropic SDK의 `models.list()` API를 활용한 동적 모델 조회
- 문자열 매칭에서 메타데이터 기반 기능 활성화로 전환
- 하드코드된 fallback 모델 제거 및 안전한 기본값 설정

---

## 2. 현재의 상태 / 문제점

### 2.1 현재 아키텍처 개요

```text
AnthropicService (src/lib/ai-service/anthropic.ts)
    ↓ extends
BaseAIService (src/lib/ai-service/base-service.ts)
    ↓ uses
LLMConfigManager (src/lib/llm-config-manager.ts)
    ↓ loads
llm-config.json (src/config/llm-config.json) [Static]
```

### 2.2 현재 구현 문제점

| 문제                            | 위치                                                    | 영향                                                                     | 심각도 |
| ------------------------------- | ------------------------------------------------------- | ------------------------------------------------------------------------ | ------ |
| **동적 모델 미지원**            | `BaseAIService.listModels()`                            | 새 Anthropic 모델이 출시되어도 config 수동 업데이트 필요                 | 높음   |
| **문자열 기반 사고 활성화**     | `AnthropicService.shouldEnableThinking()` (lines 66-75) | claude-4 등 새 모델에서 사고 기능 미활성화 가능                          | 높음   |
| **유효하지 않은 fallback 모델** | `AnthropicService.streamChat()` (line 115)              | `'claude-3-sonnet-20240229'`는 llm-config.json에 없음 → 런타임 에러 위험 | 중간   |
| **메타데이터 불일치**           | `shouldEnableThinking()` vs `llm-config.json`           | 코드 로직과 config의 `supportReasoning` 필드 불일치                      | 중간   |

### 2.3 코드 스니핏: 현재 구현

**파일:** `src/lib/ai-service/anthropic.ts`

```typescript
// 문제 1: 문자열 매칭으로 사고 활성화 판정
private shouldEnableThinking(modelName?: string, config?: AIServiceConfig): boolean {
  const model = modelName || config?.defaultModel;
  // 문제: 새 모델(예: claude-4-20250514)에서 미활성화
  return !!(model?.includes('claude-3-5') || model?.includes('claude-3-opus'));
}

// 문제 2: 하드코드된 유효하지 않은 fallback 모델
public async streamChat(options: StreamChatOptions): Promise<void> {
  const modelName = options.modelName || this.config.defaultModel || 'claude-3-sonnet-20240229'; // ❌ llm-config.json에 없음
  // ...
}
```

**파일:** `src/lib/ai-service/base-service.ts`

```typescript
// 문제 3: 정적 config만 사용, 동적 조회 없음
public async listModels(): Promise<ModelInfo[]> {
  const models = llmConfigManager.getModelsForProvider(this.getProvider());
  return models ? Object.values(models) : [];
}
```

**파일:** `src/config/llm-config.json`

```json
{
  "anthropic": {
    "models": {
      "claude-opus-4-20250514": { "supportReasoning": true, ... },
      "claude-sonnet-4-20250514": { "supportReasoning": true, ... },
      // ... 기타 모델
      // 주의: 'claude-3-sonnet-20240229'는 없음 (비추천/폐기된 모델)
    }
  }
}
```

### 2.4 검증: Anthropic SDK 모델 API 지원

✅ **확인됨:**

- Anthropic SDK (`@anthropic-ai/sdk`) 지원
- 엔드포인트: `GET /v1/models` (paginated)
- 응답 형식: `ModelInfosPage` (data 배열 + pagination)
- 자동 페이지네이션: `for await` 문법 지원
- 예시:

```typescript
for await (const model of client.models.list()) {
  console.log(model.id, model.name);
}
```

---

## 3. 변경 이후의 상태 / 해결 판정 기준

### 3.1 목표 상태

| 측면                 | Before                        | After                                     |
| -------------------- | ----------------------------- | ----------------------------------------- |
| **모델 조회**        | 정적 config (llm-config.json) | 동적 SDK 호출 + 정적 폴백                 |
| **사고 활성화 판정** | 문자열 매칭 (`includes()`)    | 메타데이터 조회 (`supportReasoning` 필드) |
| **Fallback 모델**    | 하드코드 (유효하지 않음)      | 동적 선택 (항상 유효)                     |
| **확장성**           | 수동 config 업데이트 필요     | 자동 반영 (SDK 최신 모델)                 |

### 3.2 해결 판정 기준 (Acceptance Criteria)

#### ✅ 기능 기준

1. **listModels() 오버라이드**
   - [ ] `AnthropicService.listModels()`가 `this.anthropic.models.list()`를 호출
   - [ ] SDK 응답을 `ModelInfo[]`로 정확하게 매핑
   - [ ] 네트워크 실패 시 `super.listModels()`로 자동 폴백
   - [ ] 로깅: 성공 시 로드된 모델 개수, 실패 시 에러 메시지 기록

2. **shouldEnableThinking() 리팩토링**
   - [ ] 문자열 매칭 제거, `llmConfigManager.getModel()` 사용
   - [ ] 모든 claude-opus, claude-sonnet-4 계열에서 사고 활성화 검증
   - [ ] config에 없는 모델: `false` 반환 (안전 기본값)

3. **streamChat() Fallback 개선**
   - [ ] 현재의 하드코드 모델 제거
   - [ ] 우선순위 체인: `options.modelName` > `config.defaultModel` > config의 첫 모델 > 기본값
   - [ ] 선택된 모델이 항상 유효한지 검증

#### ✅ 테스트 기준

1. **단위 테스트** (`src/lib/ai-service/__tests__/anthropic.test.ts`)
   - [ ] `listModels()`: SDK 응답 10개 모델 → ModelInfo[] 변환 검증
   - [ ] `listModels()`: 네트워크 에러 시 super.listModels() 호출 검증
   - [ ] `shouldEnableThinking()`: `supportReasoning=true` 모델에서 `true` 반환
   - [ ] `shouldEnableThinking()`: config 없는 모델에서 `false` 반환
   - [ ] `streamChat()`: 모델 선택 우선순위 검증

2. **통합 테스트**
   - [ ] UI 모델 드롭다운에서 SDK 모델 목록 로드 (E2E 시뮬레이션)
   - [ ] 챗 메시지 스트림에서 사고 기능 활성화 여부 검증

#### ✅ 호환성 기준

- [ ] 기존 API 호환성 유지 (breaking change 없음)
- [ ] 폴백 메커니즘으로 인한 성능 저하 무시할 수 있는 수준 (<100ms)
- [ ] 모든 기존 모델 (claude-3-5-sonnet-20241022 등) 계속 작동

---

## 4. 수정이 필요한 코드

### 4.1 수정 파일 목록

| 파일                                             | 변경 사항               | 영향도 |
| ------------------------------------------------ | ----------------------- | ------ |
| `src/lib/ai-service/anthropic.ts`                | 3개 메서드 추가/수정    | 직접   |
| `src/lib/ai-service/__tests__/anthropic.test.ts` | 테스트 5개 추가         | 간접   |
| `src/config/llm-config.json`                     | 변경 없음 (폴백용 유지) | 없음   |

### 4.2 상세 수정 사항

#### **4.2.1 `src/lib/ai-service/anthropic.ts` - 메서드 1: listModels() 오버라이드**

**위치:** 파일의 `AnthropicService` 클래스 내, `streamChat()` 메서드 이전

**현재 상태:** 메서드 없음 (상속받은 `BaseAIService.listModels()` 사용)

**변경 사항:**

````typescript
/**
 * Fetches available Claude models from Anthropic API.
 * Falls back to static config if SDK call fails.
 */
async listModels(): Promise<ModelInfo[]> {
  const logger = getLogger('AnthropicService.listModels');

  try {
    // SDK provides ModelInfosPage type with data array
    const response = await this.anthropic.models.list();

    if (Array.isArray(response?.data)) {
      for (const model of response.data) {
        // Map SDK ModelInfo to our ModelInfo interface
        models.push({
          id: model.id,
          name: model.name || model.id,
          contextWindow: model.context_window || 200000,
          supportReasoning: model.type === 'model' &&
                           (model.id.includes('opus') || model.id.includes('sonnet-4')),
          supportTools: true, // All Claude models support tools
          supportStreaming: true, // All Claude models support streaming
          cost: {
            inputCost: 0, // Not provided by SDK, kept from config
            outputCost: 0,
          },
          description: `Claude model: ${model.id}`,
        });
      }

      logger.info(`Loaded ${models.length} models from Anthropic API`);
      return models;
    }
  } catch (error) {
    logger.warn('Failed to fetch models from Anthropic API, falling back to static config', error);
  }

  // Fallback to static config
  return super.listModels();
}
```#### **4.2.2 `src/lib/ai-service/anthropic.ts` - 메서드 2: shouldEnableThinking() 리팩토링**

**위치:** 파일의 `shouldEnableThinking()` 메서드 (현재 lines 66-75)

**현재 상태:**

```typescript
private shouldEnableThinking(modelName?: string, config?: AIServiceConfig): boolean {
  const model = modelName || config?.defaultModel;
  return !!(model?.includes('claude-3-5') || model?.includes('claude-3-opus'));
}
````

**변경 사항:**

```typescript
private shouldEnableThinking(modelName?: string, config?: AIServiceConfig): boolean {
  const logger = getLogger('AnthropicService.shouldEnableThinking');
  const modelId = modelName || config?.defaultModel;

  if (!modelId) {
    logger.debug('No model specified, thinking disabled by default');
    return false;
  }

  // Use metadata from config instead of string matching
  const modelInfo = llmConfigManager.getModel('anthropic', modelId);

  if (!modelInfo) {
    logger.warn(`Model ${modelId} not found in config, thinking disabled`);
    return false;
  }

  return !!modelInfo.supportReasoning;
}
```

**수정 이유:**

- 메타데이터 기반 판정으로 코드-config 불일치 제거
- 새 모델 자동 지원 (config에서 `supportReasoning: true`이면 지원)
- 명확한 폴백 로직

#### **4.2.3 `src/lib/ai-service/anthropic.ts` - 메서드 3: getDefaultModel() 추가 + streamChat() 개선**

**위치:** 파일의 `streamChat()` 메서드 이전 (헬퍼 메서드)

**새 헬퍼 메서드 추가:**

```typescript
/**
 * Selects the best available model following priority order.
 * Priority: explicit option > config default > first available config model > fallback
 */
private getDefaultModel(): string {
  const logger = getLogger('AnthropicService.getDefaultModel');

  // Priority 1: Check config default
  if (this.config.defaultModel) {
    logger.debug(`Using config default model: ${this.config.defaultModel}`);
    return this.config.defaultModel;
  }

  // Priority 2: First model from config
  const configModels = llmConfigManager.getModelsForProvider('anthropic');
  if (configModels && Object.keys(configModels).length > 0) {
    const firstModel = Object.keys(configModels)[0];
    logger.debug(`Using first config model: ${firstModel}`);
    return firstModel;
  }

  // Priority 3: Safe fallback (verified to exist in current config)
  const fallback = 'claude-3-5-sonnet-20241022';
  logger.warn(`No config models found, using fallback: ${fallback}`);
  return fallback;
}
```

**streamChat() 메서드 수정 부분 (현재 line 115 근처):**

**변경 전:**

```typescript
public async streamChat(options: StreamChatOptions): Promise<void> {
  const modelName = options.modelName || this.config.defaultModel || 'claude-3-sonnet-20240229';
  // ...
}
```

**변경 후:**

```typescript
public async streamChat(options: StreamChatOptions): Promise<void> {
  const modelName = options.modelName || this.getDefaultModel();
  // ...
}
```

---

## 5. 재사용 가능한 연관 코드

### 5.1 인터페이스 & 타입 (기존, 재사용)

**파일:** `src/lib/ai-service/types.ts`

```typescript
// 이미 정의됨, 수정 불필요
export interface ModelInfo {
  id: string;
  name: string;
  contextWindow: number;
  supportReasoning: boolean;
  supportTools: boolean;
  supportStreaming: boolean;
  cost: {
    inputCost: number;
    outputCost: number;
  };
  description: string;
}

export interface AIServiceConfig {
  apiKey: string;
  defaultModel?: string;
  // ...
}
```

### 5.2 기존 유틸리티 (재사용)

**파일:** `src/lib/llm-config-manager.ts`

```typescript
// 이미 구현됨
export class LLMConfigManager {
  getModel(providerId: string, modelId: string): ModelInfo | undefined {
    // Returns model metadata or undefined
  }

  getModelsForProvider(
    providerId: string,
  ): Record<string, ModelInfo> | undefined {
    // Returns all models for provider
  }
}
```

### 5.3 로깅 유틸리티 (재사용)

**파일:** `src/lib/logger.ts`

```typescript
// 이미 구현됨
export const getLogger = (context: string) => ({
  debug: (msg: string, data?: unknown) => {
    /* ... */
  },
  info: (msg: string, data?: unknown) => {
    /* ... */
  },
  warn: (msg: string, error?: unknown) => {
    /* ... */
  },
  error: (msg: string, error?: unknown) => {
    /* ... */
  },
});
```

### 5.4 Anthropic SDK 클라이언트 (기존)

**파일:** `src/lib/ai-service/anthropic.ts`

```typescript
// 이미 초기화됨
constructor(config: AIServiceConfig) {
  super(config);
  this.anthropic = new Anthropic({
    apiKey: config.apiKey,
    defaultHeaders: {
      'anthropic-version': '2023-06-01',
    },
  });
}
```

---

## 6. Test Code 추가 및 수정 가이드

### 6.1 테스트 파일 생성

**파일:** `src/lib/ai-service/__tests__/anthropic.test.ts` (신규 또는 기존 확장)

### 6.2 테스트 케이스

#### **테스트 1: listModels() - 성공 케이스**

```typescript
describe('AnthropicService.listModels()', () => {
  it('should fetch models from SDK and map to ModelInfo[]', async () => {
    // Mock SDK response
    const mockModels = [
      {
        id: 'claude-opus-4-20250514',
        name: 'Claude Opus 4',
        context_window: 200000,
        type: 'model',
      },
      {
        id: 'claude-sonnet-4-20250514',
        name: 'Claude Sonnet 4',
        context_window: 200000,
        type: 'model',
      },
    ];

    const service = new AnthropicService({ apiKey: 'test-key' });
    jest.spyOn(service['anthropic'].models, 'list').mockResolvedValue({
      data: mockModels,
    });

    const result = await service.listModels();

    expect(result).toHaveLength(2);
    expect(result[0].id).toBe('claude-opus-4-20250514');
    expect(result[0].supportReasoning).toBe(true);
  });
});
```

#### **테스트 2: listModels() - 폴백 케이스**

```typescript
it('should fallback to super.listModels() on SDK error', async () => {
  const service = new AnthropicService({ apiKey: 'test-key' });
  jest
    .spyOn(service['anthropic'].models, 'list')
    .mockRejectedValue(new Error('Network error'));
  const superSpy = jest.spyOn(BaseAIService.prototype, 'listModels');

  await service.listModels();

  expect(superSpy).toHaveBeenCalled();
});
```

#### **테스트 3: shouldEnableThinking() - 메타데이터 기반**

```typescript
describe('AnthropicService.shouldEnableThinking()', () => {
  it('should return true for supportReasoning models', () => {
    const service = new AnthropicService({ apiKey: 'test-key' });
    // Assuming llm-config.json has claude-opus-4 with supportReasoning=true

    const result = service['shouldEnableThinking'](
      'claude-opus-4-20250514',
      {},
    );

    expect(result).toBe(true);
  });

  it('should return false for models without supportReasoning', () => {
    const service = new AnthropicService({ apiKey: 'test-key' });
    // Assuming llm-config.json has claude-3-5-haiku with supportReasoning=false

    const result = service['shouldEnableThinking'](
      'claude-3-5-haiku-20241022',
      {},
    );

    expect(result).toBe(false);
  });

  it('should return false for unknown models', () => {
    const service = new AnthropicService({ apiKey: 'test-key' });

    const result = service['shouldEnableThinking']('unknown-model-xyz', {});

    expect(result).toBe(false);
  });
});
```

#### **테스트 4: getDefaultModel() - 우선순위**

```typescript
describe('AnthropicService.getDefaultModel()', () => {
  it('should prefer config default model', () => {
    const service = new AnthropicService({
      apiKey: 'test-key',
      defaultModel: 'claude-opus-4-20250514',
    });

    const result = service['getDefaultModel']();

    expect(result).toBe('claude-opus-4-20250514');
  });

  it('should fallback to first config model if no default', () => {
    const service = new AnthropicService({ apiKey: 'test-key' });
    // Mock llmConfigManager.getModelsForProvider to return models

    const result = service['getDefaultModel']();

    expect(result).not.toBeNull();
  });
});
```

#### **테스트 5: streamChat() - 모델 선택**

```typescript
describe('AnthropicService.streamChat()', () => {
  it('should use explicit model name if provided', async () => {
    const service = new AnthropicService({ apiKey: 'test-key' });
    const createSpy = jest.spyOn(service['anthropic'].messages, 'create');

    await service.streamChat({
      modelName: 'claude-opus-4-20250514',
      messages: [],
    });

    expect(createSpy).toHaveBeenCalledWith(
      expect.objectContaining({
        model: 'claude-opus-4-20250514',
      }),
      expect.anything(),
    );
  });
});
```

### 6.3 테스트 실행 명령

```bash
# 특정 테스트만 실행
pnpm test -- anthropic.test.ts

# 모든 테스트 실행
pnpm test

# 커버리지 포함
pnpm test -- --coverage
```

---

## 7. 구현 순서 & 주의사항

### 7.1 추천 구현 순서

#### Phase 1: 저위험 리팩토링

- `shouldEnableThinking()` 메서드 리팩토링 → 단위 테스트
- `getDefaultModel()` 헬퍼 메서드 추가 → `streamChat()` 수정 → 단위 테스트

#### Phase 2: 중위험 기능 추가

- `listModels()` 오버라이드 구현 → 통합 테스트

#### Phase 3: 검증

- 전체 E2E 테스트 및 로그 검증
- `pnpm refactor:validate` 실행

### 7.2 주의사항

#### 타입 안전성

- `@ts-expect-error` 사용: SDK에서 `models.list()` 공식 지원 안 함
- 향후 SDK 버전 업데이트 시 제거 가능

#### 성능 고려

- `listModels()` 호출은 가능한 캐싱하기 (서비스 초기화 시 1회)
- UI에서 반복 호출 시 성능 저하 가능

#### 폴백 안전성

- 네트워크 에러 시 정적 config으로 자동 폴백
- `getDefaultModel()`의 fallback 모델 유효성 검증 필수

#### 로깅

- 모든 주요 경로에서 로깅 추가 (SDK 호출, 폴백, 에러)
- 프로덕션 디버깅 용이

---

## 8. 검증 체크리스트

### 구현 전

- [ ] 이 계획 문서 리뷰 완료
- [ ] 관련 팀/동료 승인 획득
- [ ] 기존 테스트 스위트 실행 확인 (기준선)

### 구현 중

- [ ] Phase 1 완료 후 `pnpm lint` 통과
- [ ] Phase 2 완료 후 `pnpm build` 성공
- [ ] 새로 추가한 테스트 모두 통과

### 구현 후

- [ ] `pnpm refactor:validate` 완전 통과
- [ ] 모든 기존 모델 작동 확인 (claude-3-5-sonnet, claude-opus, etc.)
- [ ] 새 모델 추가 시 자동 지원 확인 (mock 테스트)
- [ ] 에러 로그 검증 (폴백 시 warn 레벨)
- [ ] 통합 테스트: UI 모델 드롭다운 로드 검증

---

## 9. 참고 자료

### 관련 파일

- `src/lib/ai-service/anthropic.ts` - 주 수정 파일
- `src/lib/ai-service/base-service.ts` - 부모 클래스 참고
- `src/lib/llm-config-manager.ts` - 메타데이터 소스
- `src/config/llm-config.json` - 정적 모델 정의
- `src/lib/ai-service/__tests__/anthropic.test.ts` - 테스트 추가

### 외부 참고

- [Anthropic SDK 문서](https://docs.anthropic.com/) - `models.list()` API
- [SynapticFlow 코딩 가이드](./.github/copilot-instructions.md) - 코드 스타일
- [모델 기능 매트릭스](./docs/builtin-tools.md) - 모델별 기능

---

## 10. 이전 분석 자료

### 10.1 수행한 선행 분석

✅ **분석 완료:**

- 현재 아키텍처 전수 검토 (메시지 1-2)
- Anthropic SDK 모델 API 문서 검증 (메시지 5)
- 구현 전략 3가지 설계 (메시지 6)
- Todo 리스트 작성 (메시지 6, 8개 항목)

✅ **기술 검증:**

- SDK 엔드포인트: `GET /v1/models` (paginated)
- 자동 페이지네이션: `for await` 문법 지원
- 폴백: 정적 config 유지 가능

---

**작성일:** 2025-10-18
**작성자:** GitHub Copilot (분석 기반 AI 제안)
**상태:** 검토 대기 중
