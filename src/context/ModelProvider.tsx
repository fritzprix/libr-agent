import {
  createContext,
  useCallback,
  useMemo,
  useContext,
  FC,
  PropsWithChildren,
  useEffect,
  useState,
} from 'react';
import { AIServiceProvider, AIServiceFactory } from '../lib/ai-service';
import {
  llmConfigManager,
  ModelInfo,
  ProviderInfo,
} from '../lib/llm-config-manager';
import { useSettings } from '../hooks/use-settings';
import { getLogger } from '@/lib/logger';

const DEFAULT_MODEL_INFO: ModelInfo = {
  contextWindow: 0,
  supportTools: false,
  supportReasoning: false,
  supportStreaming: false,
  cost: { input: 0, output: 0 },
  description: '',
  name: '',
};

const logger = getLogger("ModelProvider");

interface ModelOptionsContextType {
  modelId: string;
  provider: AIServiceProvider;
  models: Record<string, ModelInfo>;
  providers: Array<ProviderInfo>;
  setProvider: (provider: AIServiceProvider) => void;
  setModel: (modelId: string) => void;
  isLoading: boolean;
  apiKeys: Record<AIServiceProvider, string>;
  selectedModelData: ModelInfo;
  providerOptions: { label: string; value: string }[];
  modelOptions: { label: string; value: string }[];
  refreshModels: () => Promise<void>;
  isRefreshingModels: boolean;
}

const ModelOptionsContext = createContext<ModelOptionsContextType | null>(null);

export const ModelOptionsProvider: FC<PropsWithChildren> = ({ children }) => {
  const {
    value: {
      apiKeys,
      preferredModel: { model, provider },
    },
    update,
    isLoading,
  } = useSettings();

  // ÎèôÏ†Å Î™®Îç∏ Î™©Î°ù ÏÉÅÌÉú (Ï£ºÎ°ú OllamaÏö©)
  const [dynamicModels, setDynamicModels] = useState<Record<string, ModelInfo>>(
    {},
  );
  const [isRefreshingModels, setIsRefreshingModels] = useState(false);

  // ÌòÑÏû¨ ÌîÑÎ°úÎ∞îÏù¥ÎçîÏùò Î™®Îç∏ Î™©Î°ù Í≥ÑÏÇ∞
  const models = useMemo(() => {
    const staticModels = llmConfigManager.getModelsForProvider(provider) || {};

    // OllamaÏùò Í≤ΩÏö∞ ÎèôÏ†Å Î™®Îç∏ Î™©Î°ù Ïö∞ÏÑ† ÏÇ¨Ïö©
    if (
      provider === AIServiceProvider.Ollama &&
      Object.keys(dynamicModels).length > 0
    ) {
      return dynamicModels;
    }

    return staticModels;
  }, [provider, dynamicModels]);

  // ÏàòÎèô Î™®Îç∏ ÏÉàÎ°úÍ≥†Ïπ® Ìï®Ïàò (ÏÉàÎ°úÍ≥†Ïπ® Î≤ÑÌäºÏö©)
  const refreshModels = useCallback(async () => {
    // OllamaÍ∞Ä ÏïÑÎãàÎ©¥ ÏÉàÎ°úÍ≥†Ïπ® Î∂àÌïÑÏöî
    if (provider !== AIServiceProvider.Ollama) {
      return;
    }

    const apiKey = apiKeys[provider];
    if (!apiKey) {
      logger.warn('No API key available for Ollama');
      return;
    }

    setIsRefreshingModels(true);
    try {
      const service = AIServiceFactory.getService(provider, apiKey);
      const modelList = await service.listModels();

      // ModelInfo[] Î∞∞Ïó¥ÏùÑ Record<string, ModelInfo>Î°ú Î≥ÄÌôò
      const modelsRecord = modelList.reduce(
        (acc, modelInfo) => {
          const key = modelInfo.id || modelInfo.name;
          acc[key] = modelInfo;
          return acc;
        },
        {} as Record<string, ModelInfo>,
      );

      setDynamicModels(modelsRecord);
      logger.info(`Manually refreshed ${modelList.length} models from Ollama server`);
    } catch (error) {
      logger.error('Failed to manually refresh models:', error);
      // ÏóêÎü¨ Ïãú Îπà Í∞ùÏ≤¥Î°ú ÏÑ§Ï†ïÌïòÏó¨ Ï†ïÏ†Å Î™®Îç∏Î°ú fallback
      setDynamicModels({});
    } finally {
      setIsRefreshingModels(false);
    }
  }, [provider, apiKeys]);

  // ÌîÑÎ°úÎ∞îÏù¥ÎçîÍ∞Ä OllamaÎ°ú Î≥ÄÍ≤ΩÎê† Îïå ÏûêÎèôÏúºÎ°ú Î™®Îç∏ Î™©Î°ù ÏÉàÎ°úÍ≥†Ïπ®
  useEffect(() => {
    const fetchOllamaModels = async () => {
      if (provider !== AIServiceProvider.Ollama) {
        // OllamaÍ∞Ä ÏïÑÎãàÎ©¥ ÎèôÏ†Å Î™®Îç∏ Î™©Î°ù Ï¥àÍ∏∞Ìôî
        setDynamicModels({});
        return;
      }

      const apiKey = apiKeys[provider];
      if (!apiKey) {
        logger.warn('No API key available for Ollama');
        return;
      }

      setIsRefreshingModels(true);
      try {
        const service = AIServiceFactory.getService(provider, apiKey);
        const modelList = await service.listModels();

        // ModelInfo[] Î∞∞Ïó¥ÏùÑ Record<string, ModelInfo>Î°ú Î≥ÄÌôò
        const modelsRecord = modelList.reduce(
          (acc, modelInfo) => {
            const key = modelInfo.id || modelInfo.name;
            acc[key] = modelInfo;
            return acc;
          },
          {} as Record<string, ModelInfo>,
        );

        setDynamicModels(modelsRecord);
        logger.info(`Auto-refreshed ${modelList.length} models from Ollama server`);
      } catch (error) {
        logger.error('Failed to auto-refresh models:', error);
        // ÏóêÎü¨ Ïãú Îπà Í∞ùÏ≤¥Î°ú ÏÑ§Ï†ïÌïòÏó¨ Ï†ïÏ†Å Î™®Îç∏Î°ú fallback
        setDynamicModels({});
      } finally {
        setIsRefreshingModels(false);
      }
    };

    fetchOllamaModels();
  }, [provider, apiKeys]); // Ï†ïÌôïÌïú ÏùòÏ°¥ÏÑ±Îßå Ìè¨Ìï®

  const providerOptions = useMemo(() => {
    const providers = llmConfigManager.getProviders();
    logger.info('üìä Available providers:', providers);
    
    return Object.entries(providers).map(([key, value]) => ({
      label: value.name,
      value: key,
    }));
  }, []);

  const modelOptions = useMemo(() => {
    logger.info('üéØ Current provider:', provider);
    logger.info('üì¶ Models for provider:', models);
    
    const options = Object.entries(models).map(([key, value]) => ({
      label: value.name,
      value: key,
    }));
    
    logger.info('üîÑ Generated modelOptions:', options);
    return options;
  }, [models, provider]);

  const selectedModelData = useMemo(() => {
    return models[model] || DEFAULT_MODEL_INFO;
  }, [models, model]);

  const setProvider = useCallback(
    (newProvider: AIServiceProvider) => {
      let availableModels: Record<string, ModelInfo> = {};

      if (
        newProvider === AIServiceProvider.Ollama &&
        Object.keys(dynamicModels).length > 0
      ) {
        availableModels = dynamicModels;
      } else {
        availableModels =
          llmConfigManager.getModelsForProvider(newProvider) || {};
      }

      if (Object.keys(availableModels).length === 0) {
        logger.warn(`No available models for ${newProvider}`);
        // Î™®Îç∏Ïù¥ ÏóÜÏñ¥ÎèÑ ÌîÑÎ°úÎ∞îÏù¥ÎçîÎäî Î≥ÄÍ≤ΩÌïòÍ≥†, Î™®Îç∏ÏùÄ Îπà Î¨∏ÏûêÏó¥Î°ú ÏÑ§Ï†ï
        update({ preferredModel: { provider: newProvider, model: '' } });
        return;
      }

      const modelEntries = Object.entries(availableModels);
      const newModel = modelEntries.length > 0 ? modelEntries[0][0] : '';

      update({ preferredModel: { provider: newProvider, model: newModel } });
    },
    [update, dynamicModels],
  );

  const setModel = useCallback(
    (newModel: string) => {
      update({ preferredModel: { provider, model: newModel } });
    },
    [provider, update],
  );

  const contextValue = useMemo(
    () => ({
      modelId: model,
      provider,
      models,
      providers: Object.values(llmConfigManager.getProviders()),
      setProvider,
      setModel,
      isLoading: isLoading || isRefreshingModels,
      apiKeys,
      selectedModelData,
      providerOptions,
      modelOptions,
      refreshModels,
      isRefreshingModels,
    }),
    [
      model,
      provider,
      models,
      setProvider,
      setModel,
      isLoading,
      isRefreshingModels,
      apiKeys,
      selectedModelData,
      providerOptions,
      modelOptions,
      refreshModels,
    ],
  );

  return (
    <ModelOptionsContext.Provider value={contextValue}>
      {children}
    </ModelOptionsContext.Provider>
  );
};

export const useModelOptions = () => {
  const context = useContext(ModelOptionsContext);
  if (!context) {
    throw new Error(
      'useModelOptions must be used within a ModelOptionsProvider',
    );
  }
  return context;
};
