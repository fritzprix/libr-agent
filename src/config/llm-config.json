{
  "providers": {
    "openai": {
      "name": "OpenAI",
      "apiKeyEnvVar": "OPENAI_API_KEY",
      "baseUrl": "https://api.openai.com/v1",
      "models": {
        "gpt-4.1": {
          "name": "GPT-4.1",
          "contextWindow": 1000000,
          "supportReasoning": true,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.003,
            "output": 0.012
          },
          "description": "Advanced model with 1M context, excellent for coding and instruction following"
        },
        "gpt-4.1-mini": {
          "name": "GPT-4.1 Mini", 
          "contextWindow": 1000000,
          "supportReasoning": true,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.00015,
            "output": 0.0006
          },
          "description": "Fast and affordable with 1M context, 83% cheaper than GPT-4o"
        },
        "gpt-4.1-nano": {
          "name": "GPT-4.1 Nano",
          "contextWindow": 1000000,
          "supportReasoning": true,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.00005,
            "output": 0.0002
          },
          "description": "Fastest and cheapest model with 1M context for low-latency tasks"
        },
        "o3": {
          "name": "OpenAI o3",
          "contextWindow": 200000,
          "supportReasoning": true,
          "supportTools": true,
          "supportStreaming": false,
          "cost": {
            "input": 0.06,
            "output": 0.24
          },
          "description": "Most intelligent reasoning model for complex multi-step problems"
        },
        "o4-mini": {
          "name": "OpenAI o4-mini",
          "contextWindow": 200000,
          "supportReasoning": true,
          "supportTools": true,
          "supportStreaming": false,
          "cost": {
            "input": 0.003,
            "output": 0.012
          },
          "description": "Fast, cost-efficient reasoning model for math, coding, and visual tasks"
        },
        "gpt-image-1": {
          "name": "GPT Image 1",
          "contextWindow": 128000,
          "supportReasoning": false,
          "supportTools": false,
          "supportStreaming": false,
          "cost": {
            "input": 0.04,
            "output": 0.04
          },
          "description": "Professional-grade image generation with text rendering capabilities"
        },
        "gpt-4o": {
          "name": "GPT-4o",
          "contextWindow": 128000,
          "supportReasoning": true,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.0025,
            "output": 0.01
          },
          "description": "Most capable GPT-4 model with enhanced reasoning and multimodal capabilities"
        },
        "gpt-4o-mini": {
          "name": "GPT-4o Mini",
          "contextWindow": 128000,
          "supportReasoning": true,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.00015,
            "output": 0.0006
          },
          "description": "Affordable and intelligent small model"
        }
      }
    },
    "anthropic": {
      "name": "Anthropic",
      "apiKeyEnvVar": "ANTHROPIC_API_KEY",
      "baseUrl": "https://api.anthropic.com",
      "models": {
        "claude-opus-4-20250514": {
          "name": "Claude 4 Opus",
          "contextWindow": 200000,
          "supportReasoning": true,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.015,
            "output": 0.075
          },
          "description": "Most intelligent Claude model for complex coding and AI agent workflows"
        },
        "claude-sonnet-4-20250514": {
          "name": "Claude 4 Sonnet",
          "contextWindow": 200000,
          "supportReasoning": true,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.003,
            "output": 0.015
          },
          "description": "Smart, efficient model for everyday use with improved coding and reasoning"
        },
        "claude-3-5-sonnet-20241022": {
          "name": "Claude 3.5 Sonnet",
          "contextWindow": 200000,
          "supportReasoning": true,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.003,
            "output": 0.015
          },
          "description": "Previous generation intelligent Claude model"
        },
        "claude-3-5-haiku-20241022": {
          "name": "Claude 3.5 Haiku",
          "contextWindow": 200000,
          "supportReasoning": true,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.0008,
            "output": 0.004
          },
          "description": "Fast and cost-effective Claude model"
        }
      }
    },
    "groq": {
      "name": "Groq",
      "apiKeyEnvVar": "GROQ_API_KEY",
      "baseUrl": "https://api.groq.com/openai/v1",
      "models": {
        "llama-3.3-70b-versatile": {
          "name": "Llama 3.3 70B Versatile",
          "contextWindow": 128000,
          "supportReasoning": true,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.00059,
            "output": 0.00079
          },
          "description": "Latest Llama model with significant quality improvements"
        },
        "llama-3.1-8b-instant": {
          "name": "Llama 3.1 8B Instant",
          "contextWindow": 128000,
          "supportReasoning": true,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.00005,
            "output": 0.00008
          },
          "description": "Fast and efficient Llama model for instant responses"
        },
        "deepseek-r1-distill-llama-70b": {
          "name": "DeepSeek R1 Distill Llama 70B",
          "contextWindow": 128000,
          "supportReasoning": true,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.00059,
            "output": 0.00079
          },
          "description": "Advanced reasoning model with distilled capabilities"
        },
        "qwen/qwen3-32b": {
          "name": "Qwen3 32B",
          "contextWindow": 128000,
          "supportReasoning": true,
          "supportTools": false,
          "supportStreaming": true,
          "cost": {
            "input": 0.0008,
            "output": 0.0008
          },
          "description": "Latest Qwen reasoning model with strong problem-solving capabilities"
        },
        "gemma2-9b-it": {
          "name": "Gemma 2 9B IT",
          "contextWindow": 8192,
          "supportReasoning": true,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.00002,
            "output": 0.00002
          },
          "description": "Google's efficient open-source model"
        },
        "meta-llama/llama-4-maverick-17b-128e-instruct": {
          "name": "Llama 4 Maverick 17B",
          "contextWindow": 131072,
          "supportReasoning": true,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.0002,
            "output": 0.0002
          },
          "description": "Preview of next-generation Llama 4 model series"
        }
      }
    },
    "google": {
      "name": "Google",
      "apiKeyEnvVar": "GOOGLE_API_KEY",
      "baseUrl": "https://generativelanguage.googleapis.com/v1beta",
      "models": {
        "gemini-2.5-pro": {
          "name": "Gemini 2.5 Pro",
          "contextWindow": 2097152,
          "supportReasoning": true,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.0025,
            "output": 0.01
          },
          "description": "Most intelligent Gemini thinking model with 2M context window"
        },
        "gemini-2.5-flash": {
          "name": "Gemini 2.5 Flash",
          "contextWindow": 1048576,
          "supportReasoning": true,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.000125,
            "output": 0.0005
          },
          "description": "Fast and efficient thinking model with 1M context"
        },
        "gemini-2.5-flash-lite": {
          "name": "Gemini 2.5 Flash Lite",
          "contextWindow": 1048576,
          "supportReasoning": true,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.000075,
            "output": 0.0003
          },
          "description": "Most cost-effective thinking model with dynamic thinking budget"
        },
        "gemini-2.0-flash": {
          "name": "Gemini 2.0 Flash",
          "contextWindow": 1048576,
          "supportReasoning": true,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.000125,
            "output": 0.0005
          },
          "description": "Agentic era model with enhanced multimodal capabilities"
        },
        "gemini-2.0-flash-lite": {
          "name": "Gemini 2.0 Flash Lite",
          "contextWindow": 1048576,
          "supportReasoning": false,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.000075,
            "output": 0.0003
          },
          "description": "Most cost-efficient Gemini model for high-throughput tasks"
        },
        "gemini-2.0-pro-experimental": {
          "name": "Gemini 2.0 Pro Experimental",
          "contextWindow": 2097152,
          "supportReasoning": true,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.0025,
            "output": 0.01
          },
          "description": "Experimental model with strongest coding performance and 2M context"
        }
      }
    }
  },
  "serviceConfigs": {
    "default": {
      "provider": "groq",
      "model": "llama-3.3-70b-versatile",
      "temperature": 0.7,
      "maxTokens": 4096,
      "topP": 1.0,
      "frequencyPenalty": 0.0,
      "presencePenalty": 0.0
    },
    "reasoning": {
      "provider": "anthropic",
      "model": "claude-sonnet-4-20250514",
      "temperature": 0.3,
      "maxTokens": 8192,
      "topP": 0.9,
      "frequencyPenalty": 0.0,
      "presencePenalty": 0.0
    },
    "advanced-reasoning": {
      "provider": "openai",
      "model": "o4-mini",
      "temperature": 0.1,
      "maxTokens": 8192,
      "topP": 0.8,
      "frequencyPenalty": 0.0,
      "presencePenalty": 0.0
    },
    "creative": {
      "provider": "anthropic",
      "model": "claude-opus-4-20250514",
      "temperature": 0.9,
      "maxTokens": 4096,
      "topP": 1.0,
      "frequencyPenalty": 0.1,
      "presencePenalty": 0.1
    },
    "fast": {
      "provider": "groq",
      "model": "llama-3.1-8b-instant",
      "temperature": 0.5,
      "maxTokens": 2048,
      "topP": 0.95,
      "frequencyPenalty": 0.0,
      "presencePenalty": 0.0
    },
    "cost-efficient": {
      "provider": "google",
      "model": "gemini-2.5-flash-lite",
      "temperature": 0.5,
      "maxTokens": 4096,
      "topP": 0.9,
      "frequencyPenalty": 0.0,
      "presencePenalty": 0.0
    },
    "long-context": {
      "provider": "google",
      "model": "gemini-2.5-pro",
      "temperature": 0.3,
      "maxTokens": 8192,
      "topP": 0.9,
      "frequencyPenalty": 0.0,
      "presencePenalty": 0.0
    },
    "coding": {
      "provider": "openai",
      "model": "gpt-4.1",
      "temperature": 0.1,
      "maxTokens": 4096,
      "topP": 0.8,
      "frequencyPenalty": 0.0,
      "presencePenalty": 0.0
    },
    "image-generation": {
      "provider": "openai",
      "model": "gpt-image-1",
      "temperature": 0.7,
      "maxTokens": 1024,
      "topP": 1.0,
      "frequencyPenalty": 0.0,
      "presencePenalty": 0.0
    }
  },
  "preferences": {
    "defaultService": "default",
    "fallbackService": "fast",
    "retryAttempts": 3,
    "timeoutMs": 45000,
    "enableCaching": true,
    "enableLogging": true,
    "costOptimization": true,
    "autoModelSelection": false
  }
}