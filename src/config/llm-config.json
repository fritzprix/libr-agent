{
  "providers": {
    "openai": {
      "name": "OpenAI",
      "apiKeyEnvVar": "OPENAI_API_KEY",
      "baseUrl": "https://api.openai.com/v1",
      "models": {
        "gpt-4.1": {
          "name": "GPT-4.1",
          "contextWindow": 1000000,
          "supportReasoning": false,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.003,
            "output": 0.012
          },
          "description": "Advanced model with 1M context, excellent for coding and instruction following"
        },
        "gpt-4.1-mini": {
          "name": "GPT-4.1 Mini",
          "contextWindow": 1000000,
          "supportReasoning": false,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.00015,
            "output": 0.0006
          },
          "description": "Fast and affordable with 1M context, 83% cheaper than GPT-4o"
        },
        "gpt-4.1-nano": {
          "name": "GPT-4.1 Nano",
          "contextWindow": 1000000,
          "supportReasoning": false,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.00005,
            "output": 0.0002
          },
          "description": "Fastest and cheapest model with 1M context for low-latency tasks"
        },
        "o3": {
          "name": "OpenAI o3",
          "contextWindow": 200000,
          "supportReasoning": true,
          "supportTools": true,
          "supportStreaming": false,
          "cost": {
            "input": 0.06,
            "output": 0.24
          },
          "description": "Most intelligent reasoning model for complex multi-step problems"
        },
        "o4-mini": {
          "name": "OpenAI o4-mini",
          "contextWindow": 200000,
          "supportReasoning": true,
          "supportTools": true,
          "supportStreaming": false,
          "cost": {
            "input": 0.003,
            "output": 0.012
          },
          "description": "Fast, cost-efficient reasoning model for math, coding, and visual tasks"
        },
        "gpt-image-1": {
          "name": "GPT Image 1",
          "contextWindow": 128000,
          "supportReasoning": false,
          "supportTools": false,
          "supportStreaming": false,
          "cost": {
            "input": 0.04,
            "output": 0.04
          },
          "description": "Professional-grade image generation with text rendering capabilities"
        },
        "gpt-4o": {
          "name": "GPT-4o",
          "contextWindow": 128000,
          "supportReasoning": false,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.0025,
            "output": 0.01
          },
          "description": "Most capable GPT-4 model with enhanced reasoning and multimodal capabilities"
        },
        "gpt-4o-mini": {
          "name": "GPT-4o Mini",
          "contextWindow": 128000,
          "supportReasoning": false,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.00015,
            "output": 0.0006
          },
          "description": "Affordable and intelligent small model"
        }
      }
    },
    "anthropic": {
      "name": "Anthropic",
      "apiKeyEnvVar": "ANTHROPIC_API_KEY",
      "baseUrl": "https://api.anthropic.com",
      "models": {
        "claude-opus-4-20250514": {
          "name": "Claude 4 Opus",
          "contextWindow": 200000,
          "supportReasoning": true,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.015,
            "output": 0.075
          },
          "description": "Most intelligent Claude model for complex coding and AI agent workflows"
        },
        "claude-sonnet-4-20250514": {
          "name": "Claude 4 Sonnet",
          "contextWindow": 200000,
          "supportReasoning": true,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.003,
            "output": 0.015
          },
          "description": "Smart, efficient model for everyday use with improved coding and reasoning"
        },
        "claude-3-5-sonnet-20241022": {
          "name": "Claude 3.5 Sonnet",
          "contextWindow": 200000,
          "supportReasoning": false,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.003,
            "output": 0.015
          },
          "description": "Previous generation intelligent Claude model"
        },
        "claude-3-5-haiku-20241022": {
          "name": "Claude 3.5 Haiku",
          "contextWindow": 200000,
          "supportReasoning": false,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.0008,
            "output": 0.004
          },
          "description": "Fast and cost-effective Claude model"
        }
      }
    },
    "groq": {
      "name": "Groq",
      "apiKeyEnvVar": "GROQ_API_KEY",
      "baseUrl": "https://api.groq.com/openai/v1",
      "models": {
        "llama-3.3-70b-versatile": {
          "name": "Llama 3.3 70B Versatile",
          "contextWindow": 128000,
          "supportReasoning": false,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.00059,
            "output": 0.00079
          },
          "description": "Latest Llama model with significant quality improvements"
        },
        "llama-3.1-8b-instant": {
          "name": "Llama 3.1 8B Instant",
          "contextWindow": 128000,
          "supportReasoning": false,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.00005,
            "output": 0.00008
          },
          "description": "Fast and efficient Llama model for instant responses"
        },
        "deepseek-r1-distill-llama-70b": {
          "name": "DeepSeek R1 Distill Llama 70B",
          "contextWindow": 128000,
          "supportReasoning": true,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.00059,
            "output": 0.00079
          },
          "description": "Advanced reasoning model with distilled capabilities"
        },
        "qwen/qwen3-32b": {
          "name": "Qwen3 32B",
          "contextWindow": 128000,
          "supportReasoning": true,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.0008,
            "output": 0.0008
          },
          "description": "Latest Qwen reasoning model with strong problem-solving capabilities"
        },
        "gemma2-9b-it": {
          "name": "Gemma 2 9B IT",
          "contextWindow": 8192,
          "supportReasoning": false,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.00002,
            "output": 0.00002
          },
          "description": "Google's efficient open-source model"
        },
        "meta-llama/llama-4-maverick-17b-128e-instruct": {
          "name": "Llama 4 Maverick 17B",
          "contextWindow": 131072,
          "supportReasoning": false,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.0002,
            "output": 0.0002
          },
          "description": "Preview of next-generation Llama 4 model series"
        }
      }
    },
    "gemini": {
      "name": "Google",
      "apiKeyEnvVar": "GOOGLE_API_KEY",
      "baseUrl": "https://generativelanguage.googleapis.com/v1beta",
      "models": {
        "gemini-2.5-pro": {
          "name": "Gemini 2.5 Pro",
          "contextWindow": 2097152,
          "supportReasoning": true,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.0025,
            "output": 0.01
          },
          "description": "Most intelligent Gemini thinking model with 2M context window"
        },
        "gemini-2.5-flash": {
          "name": "Gemini 2.5 Flash",
          "contextWindow": 1048576,
          "supportReasoning": true,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.000125,
            "output": 0.0005
          },
          "description": "Fast and efficient thinking model with 1M context"
        },
        "gemini-2.5-flash-lite": {
          "name": "Gemini 2.5 Flash Lite",
          "contextWindow": 1048576,
          "supportReasoning": true,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.000075,
            "output": 0.0003
          },
          "description": "Most cost-effective thinking model with dynamic thinking budget"
        },
        "gemini-2.0-flash": {
          "name": "Gemini 2.0 Flash",
          "contextWindow": 1048576,
          "supportReasoning": true,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.000125,
            "output": 0.0005
          },
          "description": "Agentic era model with enhanced multimodal capabilities"
        },
        "gemini-2.0-flash-lite": {
          "name": "Gemini 2.0 Flash Lite",
          "contextWindow": 1048576,
          "supportReasoning": false,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.000075,
            "output": 0.0003
          },
          "description": "Most cost-efficient Gemini model for high-throughput tasks"
        },
        "gemini-2.0-pro-experimental": {
          "name": "Gemini 2.0 Pro Experimental",
          "contextWindow": 2097152,
          "supportReasoning": true,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.0025,
            "output": 0.01
          },
          "description": "Experimental model with strongest coding performance and 2M context"
        }
      }
    },
    "fireworks": {
      "name": "Fireworks AI",
      "apiKeyEnvVar": "FIREWORKS_API_KEY",
      "baseUrl": "https://api.fireworks.ai/inference/v1",
      "models": {
        "deepseek-r1-fast": {
          "name": "DeepSeek R1 (Fast)",
          "contextWindow": 128000,
          "supportReasoning": true,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 3,
            "output": 8
          },
          "description": "State-of-the-art reasoning model optimized for math, coding, and complex problem solving"
        },
        "deepseek-r1-basic": {
          "name": "DeepSeek R1 (Basic)",
          "contextWindow": 128000,
          "supportReasoning": true,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.55,
            "output": 2.19
          },
          "description": "Cost-efficient reasoning model with strong performance across reasoning tasks"
        },
        "deepseek-v3": {
          "name": "DeepSeek V3",
          "contextWindow": 128000,
          "supportReasoning": false,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.9,
            "output": 0.9
          },
          "description": "Mixture-of-Experts model with 671B total parameters and 37B activated per token"
        },
        "accounts/fireworks/models/qwen3-235b-a22b-thinking-2507": {
          "name": "Qwen3 235B (Reasoning)",
          "contextWindow": 131072,
          "supportReasoning": true,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.22,
            "output": 0.88
          },
          "description": "Large-scale MoE model with thinking mode for complex reasoning tasks"
        },
        "qwen3-30b-reasoning": {
          "name": "Qwen3 30B (Reasoning)",
          "contextWindow": 131072,
          "supportReasoning": true,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.15,
            "output": 0.6
          },
          "description": "Efficient reasoning model with 30.5B parameters and 3.3B activated"
        },
        "qwen2.5-coder-32b": {
          "name": "Qwen2.5 Coder 32B",
          "contextWindow": 128000,
          "supportReasoning": false,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.2,
            "output": 0.2
          },
          "description": "Specialized coding model optimized for programming tasks"
        },
        "llama4-maverick-basic": {
          "name": "Llama 4 Maverick (Basic)",
          "contextWindow": 1000000,
          "supportReasoning": false,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.22,
            "output": 0.88
          },
          "description": "Next-gen Llama model with 1M context window and multimodal capabilities"
        },
        "llama4-scout-basic": {
          "name": "Llama 4 Scout (Basic)",
          "contextWindow": 1000000,
          "supportReasoning": false,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.15,
            "output": 0.6
          },
          "description": "Efficient Llama 4 variant with 1M context window"
        },
        "llama-3.3-70b": {
          "name": "Llama 3.3 70B",
          "contextWindow": 128000,
          "supportReasoning": false,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.2,
            "output": 0.2
          },
          "description": "Latest Llama 3.3 model with significant quality improvements"
        },
        "llama-3.1-405b": {
          "name": "Llama 3.1 405B",
          "contextWindow": 128000,
          "supportReasoning": false,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 3,
            "output": 3
          },
          "description": "Largest Llama model with exceptional performance across tasks"
        },
        "llama-3.1-70b": {
          "name": "Llama 3.1 70B",
          "contextWindow": 128000,
          "supportReasoning": false,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.2,
            "output": 0.2
          },
          "description": "High-performance Llama model for general use cases"
        },
        "llama-3.1-8b": {
          "name": "Llama 3.1 8B",
          "contextWindow": 128000,
          "supportReasoning": false,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.1,
            "output": 0.1
          },
          "description": "Fast and efficient small Llama model"
        },
        "mixtral-8x22b": {
          "name": "Mixtral 8x22B",
          "contextWindow": 64000,
          "supportReasoning": false,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 1.2,
            "output": 1.2
          },
          "description": "Large Mixture-of-Experts model with strong performance"
        },
        "mixtral-8x7b": {
          "name": "Mixtral 8x7B",
          "contextWindow": 32000,
          "supportReasoning": false,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.5,
            "output": 0.5
          },
          "description": "Efficient MoE model for general-purpose tasks"
        },
        "firefunction-v2": {
          "name": "FireFunction V2",
          "contextWindow": 8192,
          "supportReasoning": false,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.2,
            "output": 0.2
          },
          "description": "State-of-the-art function calling model competitive with GPT-4o"
        },
        "yi-large": {
          "name": "Yi Large",
          "contextWindow": 32000,
          "supportReasoning": false,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.2,
            "output": 0.2
          },
          "description": "High-performance model from 01.AI"
        },
        "kimi-k2-instruct": {
          "name": "Kimi K2 Instruct",
          "contextWindow": 128000,
          "supportReasoning": false,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.6,
            "output": 2.5
          },
          "description": "Large MoE model with 1T parameters and 32B active, optimized for agentic tasks"
        }
      }
    },
    "cerebras": {
      "name": "Cerebras",
      "apiKeyEnvVar": "CEREBRAS_API_KEY",
      "baseUrl": "https://api.cerebras.ai/v1",
      "models": {
        "llama3.1-8b": {
          "name": "Llama 3.1 8B",
          "contextWindow": 8192,
          "supportReasoning": false,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.0001,
            "output": 0.0001
          },
          "description": "Fast 8-billion-parameter model; ~1,800 tokens / s on Cerebras Inference"
        },
        "llama-3.3-70b": {
          "name": "Llama 3.3 70B",
          "contextWindow": 8192,
          "supportReasoning": false,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.0006,
            "output": 0.0006
          },
          "description": "High-accuracy 70-billion-parameter model; ~450 tokens / s"
        },
        "llama-4-scout-17b-16e-instruct": {
          "name": "Llama 4 Scout 17B",
          "contextWindow": 131072,
          "supportReasoning": false,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.0002,
            "output": 0.0002
          },
          "description": "Next-gen preview model with extended context"
        },
        "llama-4-maverick-17b-128e-instruct": {
          "name": "Llama 4 Maverick 17B",
          "contextWindow": 131072,
          "supportReasoning": false,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.0002,
            "output": 0.0002
          },
          "description": "Multimodal-ready Llama 4 variant"
        },
        "qwen-3-32b": {
          "name": "Qwen 3 32B",
          "contextWindow": 128000,
          "supportReasoning": true,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.0003,
            "output": 0.0003
          },
          "description": "Reasoning-focused 32-billion-parameter model"
        },
        "qwen-3-235b-a22b-instruct-2507": {
          "name": "Qwen 3 235B Instruct",
          "contextWindow": 131000,
          "supportReasoning": true,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.0006,
            "output": 0.0012
          },
          "description": "Frontier-level 235-billion-parameter Mixture-of-Experts; ~1,500 tokens / s"
        },
        "deepseek-r1-distill-llama-70b": {
          "name": "DeepSeek R1 Distill Llama 70B",
          "contextWindow": 128000,
          "supportReasoning": true,
          "supportTools": true,
          "supportStreaming": true,
          "cost": {
            "input": 0.0006,
            "output": 0.0006
          },
          "description": "Distilled 70-billion-parameter reasoning model (private preview)"
        }
      }
    }
  }
}
